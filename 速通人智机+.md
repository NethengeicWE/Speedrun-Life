# 速通知识表示与推理
## 哪有什么和解，只是十年停战
## C1：Knowledge Graph
### OverView
* 什么是知识：人类的自然语言、创作的绘画和音乐、数学语言、物理模型、化学公式等都是人类知识的表示形式和传承方式。具有获取、表示和处理知识的能力是人类心智区别于其它物种心智的重要特征。  
AI的核心是研究怎样用计算机易于处理的方式表示各种各样的知识，广义的讲，神经网络也是一种知识表示形式。
* 知识表示： 
    1. 用易于计算机处理的方式描述人脑的知识，对于AI来说数据与知识的区别在于后者支持推理
    1. 概念模型，支持推理，易于计算，人可理解
    1. 显式知识，强约束逻辑，推理不易扩散
    1. 基于连续向量的知识表示：Tensor，神经网络表示，隐式知识，强约束逻辑
* 知识图谱形式化表示
    1. 符号表示：关系事实=(head,relation,tail)
    1. 分布式表示：若干元素的连续表现形式，将词的语义分布式地存储在各个维度中

### 基本概念
1. Node：
    * 领域，概念，值，实体，字符串，数字，etc
    * 高阶三元组
1. 边：关系：概念间的相互作用
    * 类型，子类，关系，属性
1. 知识分类：场景，语言，常识，百科，领域，事实性，主观性

### History：
* 缘起：1956达特茅斯学院：加以描述，“智能的任何其他特性的每一个方面都应能被精确地使得机器可以对其进行模拟。  
解决了疑难问题，推动启发式搜索
* 发展：1970提出知识表示技术。非精确推理，归结原理
* 建立：1977费根鲍姆提出知识工程  
1990国际象棋，IBM超级问答系统  
2022ChatGPT

### 代表性知识图谱
#### 人工构建
1. worldnet
* 1985年由普林斯顿大学认知科学实验室建立，一部在线词典数据库系统，采用了与传统词典不同的方式，即按照词义而不是词形来组织  
词语被聚类成词义簇/同义词集(synset)，词义之间通过语义关系连
* 包含的知识：描述对象，对象间的语义关系，部分句法信息
* 核心概念：每一个Synset表示一个基本词汇概念
    * 例子：同反义，上下位
* 构建方法：人工构建+机器辅助
* 应用：NLP中的词义消歧，计算语义相似度，高质量Taxonomy

1. Cyc
* Cyc是一个由Douglas Lenat 在1984年启动的人工智能项目，其目的是构建一个完整的、机器可使用的本体体系和人类常识，分为OpenCyc和ResearchCyc
* 包含知识：CycL sentence表示事实、规则
* 构建方法：手工构建，CycL语言表示
    * (#$isa #$BillClinton #$UnitedStatesPresident)  
        Bill Clinton is a President of the United States.
    * (#$genls #$Tree-ThePlant #$Plant)  
        All trees are plants
* 推理引擎与运用

> 这些知识库具有相同的模型  
> * 一个知识库包含一个集合的实体    
> 猫王、李世民、赵高、唐朝、分封制...
> * 实体被划分到不同的类别中  
> 歌手(猫王)，皇帝(李世民),朝代(唐朝),制度(分封制)  
> * 类别通过上下位等关系相互关联  
> SubClassOf(歌手，人)，SubClassOf(皇帝，人)  
> * 实体和类别都通过属性和相互之间的关系来描述  
> BirthDate(李世民，598年),Has(歌手，歌曲)  
> * 关系可以通过蕴含关系来进行推理  
> 歌曲->作品，收购->持有  
> 

#### Wikipedia
* 免费的在线百科全书，游戏wiki你总懂得吧
1. DBPedia: 
* 2007年开始，其主要目标是构建一个社区，通过社区成员来定义和撰写准确的抽取模板，从维基百科中抽取结构信息并将其发布到Web上社区通过人工的方式构建了Taxonomy
* 总共280个类别,覆盖约50%的维基百科实体
* 支持SQL语言查询

1. yago
* 德国马普研究所从2007年开始的一个项目，融合WordNet和Wikipedia
* 从Wikipedia的结构中抽取信息:Infoboxes,类别..包括时间和地点标注
* 人工采样评估，1亿事实和100种关系

1. Freebase
* Metaweb公司2000年开始构建，2010年被Google收购
* 从Wikipedia和其他数据源(如IMDB、MusicBrainz)中导入知识
* 用户是Freebase知识构建的核心

#### 文本抽取：NELL
* 文本抽取知识图谱，持续运行
* 输入：本体，谓语实例，web，间歇人工干预
* 输出：巨量实例

### 通用知识图谱，领域知识图谱
* 广度与深度，面向人群不同

### 生命周期
1. 知识体系构建
    * 输入：领域，应用场景  
    * 输出：领域知识本体
1. 知识获取
    * 结构化数据/半结构
    * 非结构化数据：自然语言：识别，消歧，关系事件抽取
1. 知识融合
    * 输入：抽取出来的知识
    * 输出：知识库，置信度
1. 知识使用
    * 输入：大规模只是可
    * 输出：储存，查询，推理，应用
* 深度学习的突破：语音，图像，视频


## C2
### 经典知识表示理论
1. 定义
    * Feigenbaum：知识是经过削减、塑造、解释和转换的信息。简单地说知识是经过加工的信息
    * Bernstein：知识是由特定领域的描述、关系和过程组成的
    * Hayes-Roth：知识是事实、信念和启发式规则。从知识库的观点看，知识是某领域中所涉及的各有关方面的一种符号表示
1. 分类
    * 陈述性知识 (declarative knowledge): 用于描述领域内有关概念、事实、事物的属性和状态等
    * 过程性知识(procedural knowledge):用于指出如何处理与领域相关的信息，以求得问题的解
    * 元知识(meta knowledge): 关于知识的知识，包括怎样使用规则、解释规则、校验规则、解释程序结构等知识
1. 起源
    * Google公司对搜素引擎的开发衍生
1. 表示
    * 将知识表示与知识的运用分开处理在知识表示时，并不涉及如何运用知识的问题，是一种静态的描述方法
    * 将知识表示与知识的运用相结合知识寓于程序中，是一种动态的描述方法
1. 准则
    * 表示知识的范围是否广泛
    * 是否适于推理
    * 是否适于加入启发信息
    * 是否适于计算机处理
    * 是否有高效的求解算法
    * 陈述性表示还是过程性表示
    * 能否表示不精确知识
    * 能否在同一层次上和不同层次上模块化
    * 知识和元知识能否用统一的形式表示
    * 表示方法是否自然
### 知识表示方法
1. 谓语逻辑表示法
    * 命题：具有真假意义的陈述句
    * 逻辑连接词：且或非，蕴含等价
    * 个体词：领域内可以独立存在的课题
        * 个体常量，个体变量，个体域
    * 谓词：刻画个体性质与个体之间的关系
        * n元谓词：有n个个体符号的谓词
    * 函数：若干个体到某个个体的映射
    * 量词：个体数量属性的次
        * 全称量词，存在量词
    * 优点：精确，通用，自然，模块
    * 缺点：表示能量差，管理困难，效率低
1. 产生式表示法：用规则序列的形式描述问题的思维过程
    * 事实：一个语言变量的值/多个语言变量之间关系的陈述句
        * 确定性事实，不确定性事实（包含置信度）
    * 产生式系统：
        ```
                    推理机
                ___________
                |   控制   |
                |  /  |  \ |
                |/    |    \
               /|     |    | \
             /  |     |    |   \
           /    |     |    |     \
        规则库 -|---> 推理 -|---> 综合数据库
                |----------|
        ```
        * 推理机：推理机构，由一组程序组成，负责整个产生式系统的运行，实现对问题的求解
        * 数据库：存放问题求解过程中当前信息的结构（堆栈）
        * 正向推理：从已知事实出发，通过规则求得结论
        * 反向推理：从目标出发，反向使用规则，求得已知事实
    * 优点：有效性，自然性，一致性，模块化
    * 缺点：效率低，表示局限
1. 框架表示法：以框架理论为基础发展出来的一种结构化知识表示方式
    * 框架：描述所属对象属性的数据结构
        * 框架名，槽位（属性）侧面（描述槽）值（前两个的取值）
        * 类框架，实例框架->类属关系
    * 优点：结构化，继承性，自然性，模块化
    * 缺点：缺乏明确的推理机制，不能表示过程性知识
    * 代表性知识库：FrameNet
1. 脚本表示法：由槽组成的事件发生序列，描述过程而非静态知识
    * Winston：一个脚本是一个事件序列，包含了紧密相连的动作与改变状态的框架
    * Luger-Stubblfield：特定上下文的原型事件序列的结构化表示
        * 进入条件，角色，道具，场景，结果
    * 优点：更精确的时序和步骤
    * 缺点：表达能力受约束
1. 语义网表示法：不是语义网络，万维网的延申
    * 本质：以web数据为核心，用机器能理解处理的方式链接起来的海量分布式数据库   
    * 特征：唯一url，事物之间存在显式链接关系
    * 描述数据而设计的表示语言和工具，用于形式化描述一个知识领域内的概念，术语，关系
        1. 第一层：Unicode编码和url
        1. 第二层：XML+NS+XML Schema，表示数据内容和机构
        1. 第三层：RDF+RDF Schema，描述网上资源与类型，提供通用框架和数据继承的元数据解决方案
        1. 第四层:Ontology Vocabulary，用于描述各种资源之间的联系，揭示资源本身及资源之间更为复杂和丰富的语义联系，明确定义描述属性或类的术语语义及术语间关系
        1. 第五层:逻辑层，主要提供公理和推理规则，为智能推理提供基础。该层用来产生规则
        1. 第六层:证明层，执行逻辑层产生的规则，并结合信任层的应用机制来评判是否能够信赖给定的证明
        1. 第七层:信任层，注重于提供信任机制，以保证用户代理在网上进行个性化服务和彼此间交互合作时更安全可靠
        * 核心层为XML、RDF、ONTOLOGY，用于表示信息的语义
    * XML：详见上学期课件，此处不再赘述
    * RDF（Resource Description Framework）：资源描述框架，利用web标识符（URI）来标识事物，通过指定属性和相应的值描述资源的性质或资源间的关系
        * 数据模型：
            * 资源
            * 属性
            * 陈述：特定资源加上属性与相应的属性值就是一个陈述，资源为主体，属性是谓词，属性值为客体
    * RDFS：RDF的扩展，在原基础上提供了一组建模原语用以描述类，属性及其之间的关系
        * class ，subClassOf：描述类别层次结构
        * Peoperty：属性层次结构
        * domain，range：声明属性所应用的资源类和属性值类
        * type：声明一个资源是一个类的实例
        * 允许定义自己的词汇表
    * 优点：简单，易扩展，包容性，易综合
    * 缺点：不能准确描述语义，没有推理模型
1. 本体表示法：通过对概念的雅阁定义与概念间的关系来确定其精确含义，表示共同认可，共享的知识
    * 概念模型：本体通过抽象客观世界得到的模型
    * 明确性：没有歧义；形式化：可被处理；共享：共同认可的知识
    * 组成：O={C,R,F,A,I}
        * C：概念/类；R：关系；F:函数；A；公理axiom；I：实例instance；
    * OWL：语义网上推荐的表示很替的语言
        * 衍生：OWL Lite；OWL DL；OWL Full；
        * 建模原语：类运算式
1. 知识图谱：
    * 实体：现实中可区分，可识别的事物和概念
    * 关系：实体间的语义关联
    * 事实：陈述两个实体间关系的断言
    1. 狭义知识图谱：具有图结构的三元组知识库
        * 实体作节点，事实作边
    1. 分布式知识表示
        * 位移距离模型：TransE
        * 语义匹配模型：神经网络
    1. 模型训练
        * 开放世界假设：不在知识图谱中的事实是错误的/缺失的
        * 封闭世界假设：但凡不在图谱中出现的事实都是错误的
## C3
### 构建方法
* 人工
    1. 确定领域与任务
        * 与具体的领域密切相关，需要了解具体的应用任务，不能抛开领域建立一个广泛使用的产品
    1. 体系复用
        * 知识体系具有很强的抽像性和概括性
    1. 罗列要素
        * 希望在图谱中出现的要素列表，包括概念，属性，关系
    1. 确定分类体系
        * 将概念要素组织成层级结构的分类体系：自顶向下/自底向上
    1. 定义属性与关系
    1. 定义约束
* 自动
    * 基于非结构化数据的知识体系学习：利用自然语言处理工具对文本进行分词，句法分析，命名实体识别等预处理，再利用模板匹配，统计学习从文本抽取重要信息，包括领域概论，实例与概念间的关系
        * 基于结构化/半结构化
    1. 领域概念抽取：抽取关键元素，包括实体类别名，属性名，关系
        * 抽取候选术语
        * 属于过滤
        * 术语合并
    1. 分类体系构建：获取不同概念间的继承关系
        * 基于词典
        * 基于统计
    1. 概念属性与关系抽取：概念抽取
### 知识融合
1. 融合方向
    * 竖直方向：高层通用本体与底层领域本体或实例数据
    * 水平方向：融合相同层次的知识图谱
1. 融合对象
    1. 框架匹配：对概念，属性，关系等知识描述体系进行匹配融合
        * 元素级匹配：字符串，词向量
        * 结构级匹配：考虑其他元素的影响，相似的概念具有相似的概念结构
    1. 实体对齐：对齐合并相同的实体完成知识融合，可能有冲突，需要单独处理
        * 成对/协同实体对齐
        * 表示学习方法：计算相似度
1. 冲突检测与消解
### 本体
* 概念：通过对概念，术语及其相互关系的规范化描述，勾画出某一领域基本知识体系和描述语言，是共享概念模型的明确的形式化规范说明
    * 概念化，显式，形式化，共享
* Ontology vs knowledge base：前者共享概念化的规范，涉及概念，关系，公理，后者服从于前者控制的知识单元的载体
* 知识的其他组织形式
    1. Ontology：树状结构，不同层节点之间是严格的潜在语义分析关系，可以推理知识，不能处理二义性
    1. Taxonomy：树状结构，非严格关系，可以处理二义性，不能推理于概念冗余
    1. Folksonomy：类别标签，更加开放，能涵盖更多概念，但不能进行标签管理
    1. 其他形式：结合2，3，但是覆盖的类别很少，开放式标签冗余，不规范
* Ontology Annotation 语义注释 Population 本体总体 Learing 本体学习
    * 手工构建Domain Ontology很累，自动构建用不了
* Terminology：术语提取，语言方法
* Synonyms 同义词：利用外部资源，基于统计的方法
* WordNet：将英语的名词，动词，形容词，副词组织为Synsets，每一个synset为一个基本的词汇概念
* 应用：信息融合，多知识库回答，

## C4
### 实体识别
1. 命名实体：现实世界中具体或抽象的实体，可以包含时间，数量等
    * 识别命名实体：实体边界识别，确定实体类别
    * 特点：时间，日期，货币等具有明显规律；中文人名，地名等用字灵活，难度较大
        * 中文识别难点：用词广范，机构名不稳定，长度不定
        * 特点：词法角度：偏正式复合词，句法角度：名词短语，中心语
        * 音译名识别难点：难以划分内部结构，上下文差别大
    1. 任务概述：识别出文本中实体的命名性指称项，标注类别
        * 实体类，时间类，数字类
        * 人名，地名，组织名，时间，日期，百分比，货币
    1. 方法
        1. 基于规则的方法：准确率高，直观，但昂贵，移植性差
            * 定制简单的基本规则，通过错误分析改进规则
            * 字符串完全匹配或部分匹配：正向最大匹配，逆向最大匹配，最短路径
        1. 基于机器学习的方法：耐操，灵活，较客观，但需要人工标注数据，搜素空间大
            * 基于特征：上下文特征，内部特征
###  **条件随机场CRF**：给定一组输入随机变量条件下另一组输出随机变量的条件概率分布模型
* 特点：假设输出的随机变量构成马尔可夫随机场
    * 自然语言处理可以转为序列结构的标注问题
    * CRF：判别式模型，可以处理复杂特征；HMM：生成式模型，难以考虑复杂特征,ME:判别式模型，可以使用任意复杂的特征函数，只能建模观察序列和某一状态的关系
* 内容：
    1. 概率无向图模型：用图表示概率分布：设有联合概率分布P(Y)，Y是一组随机变量，由图G=(V,E)表示概率分布P(Y),即在图G中，一个节点**v**表示一个随机变量$Y_{v}$,边**e**表示随机变量之间的概率依赖关系
        > 回忆一下联合随机变量：以二元为例，x轴为概率1，y为概率2
        * 马尔可夫性：给定随机变量组$Y_{o}$的条件下$Y_{u}和Y_{v}$是条件独立的
            * 成对：其中u和v是无向图G中任意两个没有链接的节点，o为其他节点
            * 局部：o是与v连接的所有节点，u是除此之外的所有节点
            * 全局：u和v是被节点集合o分离的任意节点集合
        * 满足上面三种性质，则称此联合概率分布为马尔可夫随机场
        * 因子分解：将随机场模型的联合概率分布表示为最大团上的随机变量函数的乘积形式  
            * 团：无向图中任何两个节点均有边连接的节点子集（全连接）
            * 最大团：不能在加入任何一个无向图内节点以形成更大的团的团
        * 条件随机场：设条件概率分布P(Y|X)，若随机变量Y构成一个无向图表示的马尔科夫随机场，则称P为条件随机场
        * 线性链条件随机场：如果X，Y为线性链表示的随机变量序列，给定X，则P(Y|X)构成线性链条件随机场
            * $P(y|x) = \frac {1}{Z(x)} exp(\sum _{i,k} \lambda_{k}t_{k}(y_{i-1},y_{i},x,i)+\sum_{i,l}\mu_{l}s_{l}(y_{i},x,i))$ 
            * $t_{k},s_{l}$：特征函数
            * $\lambda_{k},u_{l}$：对应权值
        * Qize：输入观测$X=(X_{1},X_{2},X_{3})$,输出标记为$Y=(Y_{1},Y_{2},Y_{3})$，求解方法：  
        $\sum _{k=1}^{5}\lambda_{k}·\sum _{i=1}^{5}t_{k}(y_{k},y_{k-1},x,k)+\sum _{k=1}^{5} \mu_{k}·\sum_{i=1}^{5}s_{k}(),其中\lambda_{k}，t_{k}()，\mu_{k}，s_{k}()均由题目给出$
        * 简化形式：用$w_{k}$表示特征$f_{x}(x,y)$的权值：$\left\{\begin{matrix} \lambda_{k},k=1,2...K_{1} \\ \mu_{1}, k=K_{1}+l,l=1,2...K_{2}\end{matrix}\right. $   
        $P(y|x) = \frac {1}{Z(x)} exp(\sum _{k=1}^{K} w_{K}f_{K}(y,x)$
        * 矩阵形式：对观察序列x的每一个位置定义一个m阶矩阵
            * 例子：3个输入观测，3个输出标记。从star到stop的所有走法即2^3个，路径内相乘，路径间相加
        * 概率计算问题：前向-后向算法
        * 解码问题：Viterbi搜索算法：预测问题成为非规范化概率最大的最优路径问题，只需计算非规范化概率
            * 例子：$max\sum_{i=1}^{3}w·F_{i}(y_{i-1},y_{i},x)$  
            i=1时只需计算star-> $\delta(1) or \delta(2) $的概率;  
            i=2时以$\delta(1) or \delta(2) $为起点计算到下一个1/2的概率：  
            $\delta_{2}(1)=max[\delta_{1}(1)+f(),\delta_{1}(2)+f()]$  
            $\delta_{2}(2)=max[\delta_{1}(1)+f(),\delta_{1}(2)+f()]$  
            $其中f()=\sum _{i,k} \lambda_{k}t_{k}(y_{i-1},y_{i},x,i)+\sum_{i,l}\mu_{l}s_{l}(y_{i},x,i)$,$y_{i-1}为上个节点，y_{i}为当前节点$  
            以最后的节点反推最优路径
* 基于CRF的命名实体识别：对每个汉字标注对应实体类型的BIO标记；特征函数可以构建不同种类的特征如上下文，词性，词表；CRF模型的参数训练，测试
* 基于神经网络的方法：LSTM（长短期记忆网络）+ CRF
* 细粒度实体识别：类别更多，具有层次结构，难点在类别指定，语料标注，实体识别方法
* 实体扩展：由种子实体扩展到该类别的其他实体，具有目标类别，目标数据领域开放的特点，能提高问答系统性能，垂直领域信息抽取的效果
* 基于模板的实体抽取：通过预先定义号的上下位关系的语义模版，可以计算目标实体与种子实体的置信度
* 基于统计的实体抽取：分析整个语料的统计信息得到候选的分布信息，计算候选与种子的分布相似度作置信度
* 种子处理：衡量种子实体的质量，选取高质量种子
* 结果过滤：种子的歧义性，计算候选与错误候选的相似度，排除相似度过高的
## C5
### 实体消歧
1. 定义：一个实体指称可对应多个现实世界实体
    * 定义为六元组：待消歧实体名，待消歧实体名的目标列表，待消歧实体名的文档集合，待消歧实体指称项，任务所需背景知识。待消歧实体指称项 + 背景知识 -> 待消歧实体名的目标列表表示消歧函数
    * 结构化文本消歧
    * 非结构化文本消歧
### 基于聚类的实体消歧
* 思路：同一指称具有近似的上下文，利用聚类算法进行消歧
    * 基于表层特征的指称项相似度计算
    * 基于扩展特征的指称项相似度计算
    * 基于社会化网络的指称项相似度计算
* 核心问题：选取何种特征表示指称项，研究集中在实体指称项的语义表示，通过扩展特征提高消歧精度
    * 词袋模型：利用待消歧实体周边构造向量，利用向量空间计算相似度，进行聚类
    * 语义特征：利用SVD挖掘语义信息，利用词袋与浅层语义特征，共同表示指称项，余弦相似度
    * 社会化网络：对网页进行聚类
    * 维基百科知识：链接关系反映语义相关度，用实体上下文的维基条目对实体进行向量表示
    * 多源异构语义知识融合：多个知识源，需要处理等同概念
### 基于实体链接的实体消歧
* 任务：给定实体指称项与所在文本，链接到给定知识库的相应实体上
    * 链接候选过滤，过滤到大部分不可能指向的实体，再进行实体链接
* 利用上下文获取缩略语候选实体
* 实体链接：计算相似度，最高者链接
    * 向量空间模型
    * 主题一致性：候选实体概念与指称上下文中的其他实体概念的一致性程度
    * 协同实体链接：将单篇文档的协同实体链接视作优化任务
        * 同一篇文档中实体见具有语义相关性，利用pairwise优化策略
    * 基于图的协同链接：采用图方法考虑目标实体的语义关联。指称项与实体之间的关系，实体之间的语义关系
    * 神经网络/基于深度学习的方法
    * 词袋子模型计算相似度
    * 类别特征：针对候选实体文本内容太短导致相似度出问题，加入指称项与候选实体类别的共同特征
        * 训练SVM分类器对候选实体进行链接，训练数据由Wikipedia的超链接获得
    * 实体流行度：考虑实体的背景知识，融入到实体链接的过程中，考虑实体流行度（概率）名称知识（指称指向实体e的概率）上下文知识（实体出现在特定上下文环境c的概率）
    * 跨语言实体链接：利用双语隐含主题模型将实体指称项与候选实体映射到同一个主题空间中
    * 结构化数据中的实体链接：利用实体的流行度和实体共现类型去消歧
    * 社交数据中的实体链接：利用tweet的用户信息

## C6
### 任务概述
* 任务分类
    * 面向结构化/半结构化/非结构化文本
    * 句子级/语料级
    * 限定域。开放域关系
    * 二元/多元关系
* 定义：自动识别由一对概念和联系这对概念的关系构成的相关三元组
* 结构化文本学习：信息块识别，模板学习，属性值抽取
* 非结构化文本：
### 限定域关系抽取：
* 任务：给定实体关系类别，给定语料，抽取目标关系对
* 语料：精选，已定义
* 抽取方法：主要使用统计机器学习
    * 特征向量：从自由文本及其句法结构中抽取出个各种词汇特征与结构化特征
        * 实体词汇与上下文特征
        * 实体类型及其组合特征
        * 交叠特征：实体或词组块是否在同一个名/动/介词短语中
        * 句法树特征
    * 核函数：用两个句法树之间的公共子树衡量相似度
        * 标准卷积核数
        * 上下文相关卷积树核函数
    * 神经网络
        * 递归神经网络RNN：更多考虑句法，但依赖句法分析工具
        * 卷积神经网络CNN：卷积操作完成句子信息的获取，不需要NLP
            * 局部连接，权重共享，采样
            * 参数远少于全连接
        * 循环神经网络RNN：自动捕获句子级分析
            * 反馈神经网络：全部/部分神经元可以接受其他神经元或自身的信号
            * 至少一个包含反馈连接的神经网络结构，可以沿loop流动
            * 应用：命名实体识别，文本分类，关系分类
            * 参数学习：$h_{t}=\varphi (Wx_{t}+Uh_{t}+b),其中UWV为矩阵，b是向量$
            * 变体：双向循环：两条相反的线，接受相同的输入，贡献相同的输出
            * 变体：层叠循环：输入作为第一节点的输入，横纵向传递节点信息
        * 多层前馈神经网络：相邻两层的任何两个不同层神经元间存在连接
            * 不能处理变长数据
* 处理过程：抓取符号与数值特征
* 基于语言单元的语义表示
    * 本质：用数值表示各个语言单元的语义
    * 词表示：基本语言单元
        * 人工方法：刻画之间的多维度关系
        * 深度学习：数值化方法表达语义信息
    * 分布表示：词向量
        * 分布假说：上下文相似的词 -> 词义相似
        * 词表示学习：上下文的表示，相似度的衡量，分布式表示学习通过聚合关系进行建模
            * 传统方法：分布的角度建模：LSA，Brown Clustering
            * 神经网络：NNLM，skip-gram，CBOW
                * NNLM：三层前馈神经网络，输入n-1，预测n，实现词向量的表示学习
                * skip-gram，CBOW：去除隐藏层和词序
* 更大语言单元的语义表示
    * 组合语义：复杂对象的意义是由各组成部分的意义以及组合规则决定
        * 模型：局部空间的特征提取，词语之间的词序关系
        * 基于卷积网络的关系抽取：通过CNN学习文本语义特征，不需要人工设计，利用词向量信息作为词汇级特征，CNN捕获句子级特征
    * 长短时记忆神经网络LSTM：RNN的一个变体，有效解决其梯度爆炸或消失问题。通过引入一组记忆单元，允许网络何时遗忘何时更新
        * 接受上一个节点的数据与当前输入：
            * 输入门$i_{t}$：，0-1向量，控制记忆单元加入多少新信息
            * 遗忘门$f_{t}$：0-1向量，控制记忆单元遗忘多少信息
            * 输出门$o_{t}$：0-1向量，控制记忆单元输出多少信息
            * 输入控制$u_{t}$：与输入门决定当前输入对记忆单元的贡献
            * 记忆单元$c_{t}$：记录历史信息
        * 利用LSTM作关系抽取：
            * 利用双向LSTM编码每个词的表示
    * 实体与关系联合抽取：对每个关系将其与begin，inside，end，single与序号1，2组合
        * 额外other标签
        * 标注方法：LSTM+CRF，LSTM*2，LSTM*2+bias
### 开放域关系抽取：
* 新的抽取方式：，开放抽取，知识监督抽取
    * 按需抽取：Bootstrapping，模板生成->实例抽取->迭代至收敛，通过引入负实例限制语义漂移
    * 开放抽取：通过识别表达语义关系的短语抽取实体间关系，同时使用句法和统计数据过滤抽取出来的三元组
        * 无需预先定义关系类别，但是语义没有归一化，同一关系有不同表示
        * eg：Web Page，离线训练集产生->离线分类器训练->在线关系抽取->在线关系可信度评估
        * eg：Machine Reading
        * eg：Wikipedia：在infobox抽取关系信息，在Wikipedia条目中进行回标，产生训练语料
## C7
### 事件抽取：任务概述
* 信息抽取中的难点：依赖实体与关系抽取
* 事件定义：没有明确定义，事件是发生在某个特定的时间点或时间段、某个特定的地域范围内，由一个或者多个角色参与的一个或者多个动作组成的事情或者状态的改变
* 事件抽取：从自然语言文本中抽取出用户感兴趣的事件信息并以结构化的形式呈现出来，如什么人，什么时间，在什么地方，做了什么事。
* TDT，Topic Detect and Tracking：新闻报告切分，新事件识别，报道关系识别，话题识别与跟踪
    * ACE：Automatic Content Extraction
### 限定域事件抽取
* 基于模式匹配：可移植性差、召回率低
    * 平面模式主要基于词袋等字符串特征构成模式
    * 结构模式更多地考虑了句子的结构信息，融入句法分析特征
    * 缺点：领域相关，扩展性差，需要大量人工标注
* 基于机器学习：主要采用统计机器学习的方法，将事件实例转换成高维空间中的特征向量或直接用离散结构来表示
    * 基于特征向量方法：如何获取各种有效的词法、句法、语义等特征，并把它们有效地集成起来，从而产生描述单词或者词组触发事件和候选事件元素扮演事件角色的各种局部特征和简单的全局特征；
        * 基于句子级信息：句子级特征（传统特征+多分类器）
        * 基于篇章与背景信息的
    * 基于结构的方法：将事件抽取看成一个结构预测的问题。如何建模事件的结构并有效地挖掘反映事件的结构化的信息及特征
        * 传统方法：将事件抽取分成多个步骤错误会由上层向下层传递；没有考虑触发词和事件元素之间的相互影响
        * 方法：将事件抽取看成一个结构预测问题，利用beam search缩小搜索解空间
    * 基于神经网络的方法：如何设计合理的网络结构，从而捕捉更多的信息，进而更准确的完成事件的抽取，CNN，RNN，MLN多层感知机
        * 基于动态最大池化技术的卷积神经网络，传统方法的词汇特征：过于依赖人工，而且是一种独热表示，缺乏语义
            * 方法：DMCNN
            * 由4部分组成：word-embedding learning; lexical-level；feature representation；sentence-level feature extraction；argument classifier output
            * 传统的CCN利用最大池化技术，选取最大值代表每个feature map，但是事件抽取任务中一句话存在两个或者多个事件，所以提出动态最大池化技术来根据trigger和argument候选的位置，在不损失最大值的前提下，获取更多的有用信息
        * 基于有监督关注机制的多层感知机模型：事件角色为事件识别任务提供重要线索
            * 构建标准关注向量：只关注角色词/同时关注角色词及其周围的词，距离角色词越近的词受到的关注度越高
        * 融合FrameNet的事件识别方法：语言学家定义及标注的语义框架资源
            * 结构相似性：框架：一个词法单元和若干框架元素；事件： 一个触发词和若干事件角色
### 开放域事件抽取
* 核心思想：如果两个词出现在相同上下文中且用法相似，则这两个词的意思接近，因此在事件抽取任务中，如果候选事件触发词/候选事件元素具有相似的语境，那触发词倾向于触发相同类型的事件，相应的候选事件元素倾向于扮演相同的事件元素
* 基于内容特征的事件抽取
    * 文本表示：对表示时间的句子、段落或者文档进行预处理，并表示为统一的特征形式，为后面的模块做准备
    * 事件聚类与新事件发现：基于文本表示，利用无监督方法将同类事件表示聚类，并发现新事件
* 基于异常检测的事件抽取
    * 基本假设：某个重大事件的发生会导致新闻媒体或社交网络上涌现大量的相关报道或讨论；反之关于某一主题的报道或讨论突然增多表明某一重大事件的发生
* 基于世界知识/语言学知识的事件语料大规模自动生成方法
    * 现有问题：有监督的事件抽取过分依赖人工标注的数据；无监督的事件抽取的结果没有规范的语义标签
    * 动机：自动生成标注语料，远距离监督的方法在关系抽取中取得成功
    * 方法：利用世界知识和语言学知识自动生成大规模事件语料
### 事件关系抽取
* 核心任务：以事件为基本语义单元，实现事件逻辑关系的深层检测和抽取
* 事件共指关系：当两个事件指称指向真实世界的同一个目标事件，则认为这两个事件具有共指关系
    * 核心问题：计算两个事件指称之间的相似度
    * 两类特征：事件指称的文本语义相似度；事件类型和事件元素之间的相似度
* 事件因果关系：反映了事件间先后相继、由因及果的一种关系
* 子事件关系和事件时序关系：子事件关系反映了事件之间的粒度和包含关系；事件时序关系是指事件在时间上的先后顺序，这样有助于厘清事件发生的先后顺序，且能辅助其他事件关系的发现。主要集中在英文文本上
* 无监督学习叙事事件链
    * 背景：指围绕主导参与者发生的部分有序的一系列事件
    * 事件表示：利用主导参与者和事件指示词之间的句法角色表示事件
    * 方法：将所有事件当做候选，选择候选中和给定的n个事件互信息之和最大的事件作为答案
    * 事件框架学习：
        * 基于模板的事件抽取系统
            1. 从文本语料中抽取事件元素
            1. 对抽取到的事件元素进行初步聚类（相似度算法）
            1. 对每个聚类结果，在搜索引擎中搜索类内的事件元素，将返回的文档作为扩充语料。
            1. 利用扩充语料对每个初步聚类结果内的元素进行再聚类，再聚类的结果作为事件框架（每个聚类结果是一个事件，结果内的元素是该事件的元素
        * 大规模语料中生成事件框架
            1. 用关系抽取的方法（Reverb等）获得大量三元组<arg1, rel, arg2>
            1. 根据这些三元组在文档中的共现信息建立一个无向图，边权反应两个元组共现的可能性
            1. 选取图中边权最高的一些点作为种子，每个种子认为是一个事件的中心
            1. 针对每个种子，利用Personalized PageRank算法求解和其最相关的点集，每个点集表示一个事件
        * 应用：生成故事大纲，预测新事件

## C8
### 知识图谱的存储
* 基于表结构的存储：利用二维的数据表对知识图谱中的数据进行存储
    * 三元表组：事实是三元组，可以设计一张三元组表用于存储知识图谱中所有的事实
        * 缺点：单表的规模太大，复杂查询在这种存储结构上的开销巨大
    * 类型表：为每种类型构建一张表，同一类型的实例存放在相同的表中。列表示属性，行存储该类实体的一个实例
        * 缺点：大量数据字段的冗余存储（如同属多个类别的实例会被多次存储）；并非每个实体在所有属性或关系上都有值
    * 考虑层级关系的类型表：每个类型的数据表只记录属于该类型的特有属性，不同类别的公共属性保存在上一级类型对应的数据表中
        * 缺点：必须知道类型才能确定查找的数据表；多表连接开销巨大；数据表间复杂的关系造成数据管理困难
    * 关系数据库：以二维表结构对数据进行组织和存储。
        * 属性 (attribute)：表中的每一列称为一个属性，用来描述实体集的某个特征。每个属性都有自己的取值范围，称为域
        * 元组 (tuple)：表中的每一行由一个实体的相关属性取值构成，称为元组，相对完整地描述了一个实体。元组中的一个属性值称为分量
        * 限制：
            * 必须是基本数据类型；属性所有值必须是同类型、同语义的；属性的值只能是域中的值；属性必须有唯一的名字；不允许有重复的行
        * 候选码：能够唯一标识元组的最小的属性集合
        * 主码：一般选择单属性组成的候选码作为主码
        * 外码：作为其他表的候选码的属性（组）、
        * 主属性与非主属性：包含在任何候选码中的属性称为主属性；反之亦然
        * 关系数据库完整性约束：通过表和属性上定义的规则保证数据的正确性和一致性
            * 域完整性：规定属性取值必须在其值域中
            * 实体完整性：元组（记录）在构成主码的属性上不能有空值且主码的值不能相同
            * 参照完整性：一个外表的外码取值必须是其主表主码的存在值或空值
        * 操作语言：SQL，独立于关系数据库本身，独立于使用的机器、网络和操作系统
            * 插入 (INSERT)：在一个表中插入一条或多条新记录。
            * 修改 (UPDATE)：在一个表中修改满足条件的记录的某些字段的值。
            * 删除 (DELETE)：从一个表中删除一条或多条满足条件的记录。
            * 查询 (SELECT)：从一个或多个表中提取满足条件的数据、生成计算列或汇总数据。
        * 其他数据库存储系统：DB2，Oracle，SQL Server，PostgreSQL，MySQL

* 基于图结构的存储：利用图的方式对知识图谱中的数据进行存储据进行存储：将实体看做节点，关系看做带有标签的边
    * 核心概念：图数据库基于有向图，其理论基础是图论。节点、边和属性是图数据库的核心概念
        * 节点：节点用于表示实体、事件等对象
        * 边：边是指图中连接节点的有向线条，用于表示不同节点之间的关系
        * 属性：属性用于描述节点或者边的特性
    * 常见存储系统：OrientDB，HyperGraphDB，InfiniteGraph，InfoGrid，InfoGrid

### 知识图谱的检索
大部分数据库系统通过形式化的查询语言为用户提供访问数据的接口
* SQL：
    * 组成
        1. 数据查询语言DQL，用来对已存在的数据库中的数据按照指定的组合、条件表达式或排序进行检索->SELECT
        1. 数据操纵语言DML，用来改变数据库中的数据，分为插入、修改、删除三种操作->INSERT, UPDATE, DELETE
        1. 数据定义语言DDL，用来创建数据库中的各种对象，包括数据库模式、表、视图、索引、同义词、聚簇等->CREATE, DROP, ALTER
        1. 数据控制语言DCL，用来授予或回收访问数据库的某种特权，控制数据操纵事务的发生时间及效果、对数据库进行监视等->GRANT, REVOKE
    * 数据查询:   
        1. SELECT <目标表的列名或列表达式序列> FROM <基本表名和/或视图序列>   
            * select子句可以是表达式
            * DISTINCT消除相同项
        1. [ WHERE <行条件表达式>]   
            * 满足条件的表达式元组:比较,确定范围/集合,字符匹配,逻辑运算
        1. [ GROUP BY <列名序列> ]    
            * 指定列分组
        1. [ HAVING <组条件表达式> ]  
            * 满足组条件的组
        1. [ ORDER BY <列名 [ ASC|DESC ], … >]  
            * 输出排序,ASC升DESC降
        * 其他细节:
            * 所有情况为 * 
            * 聚合函数: 通过聚合函数，可以把某一列中的值形成单个值
                * 计数COUNT,总和SUM,平均值AVG,最大值MAX,最小值MIN
    * 数据操纵:
        1. INSERT INTO 表名 [ (<属性列1> [ ,<属性列2>, … ]) ] 
            * 可以只加表名,按顺序插入元组
        1. VALUES ( <常量1> [ ,<常量2>, … ] )
    * 数据修改
        1. UPDATE <表名SET> | <列名>=<表达式> [ , <列名>=<表达式>, … ] 
        1. [ WHERE 行条件表达式 ]
    * 数据删除:
        1. DELETE FROM <表名> 
        1. [ WHERE 行条件表达式 ]
    * SPARQL语言:是由W3C为RDF数据开发的一种查询语言和数据获取协议   
        * 数据插入：NSERT DATA <三元组数据>  
        * 数据删除: DELETE DATA <三元组数据>
        * 数据操纵:删除与插入,没有更新:DELETE DATA/INSERT DATA
        * 数据查询:
            1. SELECT:查询mv1的导演与编剧
            ```
            prefix ns: <http://example.org/ns#t>
            SELECT ?director ?writer
            WHERE {
                <http://example/movie1> ns:director ?director.
                <http://example/movie1> ns:writer ?writer.
            }
            ```
            1. ASK:是否满足条件:是否存在p4导演的电影
            ```
            ASK {?movie ns:director <http://example/person4>}
            ```
            1. DESCRIBE:查询指定资源相关的RDF数据:p4导演的所有电影相关信息
            ```
            DESCRIBE ?movie
            WHERE {?movie ns:director <http://example/person4>}
            ```
            1. CONSTRUCT:用于生成指定模式的RDF图
            ```
            CONSTRUCT {
                ?movie a ns:Movie
                ?movie ns:director ?director
            }
            WHERE {
                ?movie ns:writer <http://example/person3>
                ?movie ns:director ?director
            }
            ```
### Summary
* 知识图谱是一种有向图结构，描述了现实世界中存在的实体、事件或者概念以及它们之间的相关关系
* 知识图谱中的知识是通过RDF的结构进行表示的，其基本构成单元是事实，每个事实被表示为一个形如<subject, predicate, object>的三元组
* 知识图谱的目标是构建一个能够刻画现实世界的知识库，为自动问答、信息检索等应用提供支撑。因此，对知识的持久化存储并提供对目标知识的高效检索是合格的知识图谱必须具备的基本功能
* 按照存储方式的不同，知识图谱的存储可以分为基于表结构的存储和基于图结构的存储。
    * 基于表结构的存储：利用二维的数据表对知识图谱中的数据进行存储: 三元组表、类型表、关系数据库
        * 三元组：知识图谱中的事实是一个个的三元组，一种最简单直接的存储方式是设计一张三元组表用于存储知识图谱中所有的事实
        * 类型表：为每种类型构建一张表，同一类型的实例存放在相同的表中。表的每一列表示该类实体的一个属性，每一行存储该类实体的一个实例
    * 基于图结构的存储：利用图的方式对知识图谱中的数据进行存储:图数据库

## C9
### 简介与任务分类
* 知识推理是人工智能应用迈向更高级认知智能的重要技术。包括知识补全和知识问答。
* 知识补全：面向知识库或者知识图谱的事实补全。利用已知知识预测未知的隐含知识，利于完善现有知识图谱
    * 三元组分类：补全时选一边连接任意两个实体，构建新的三元组
    * 连接预测
    * 简单推理：将问题转化为图谱上三元组的查询或者三元组序的查询。对于缺失的需要使用推理
    * 复杂推理：表示成多个链接组成的非链式或有嵌套的复杂结构时，需要推理
* 归纳推理：从特殊到一般的过程。根据部分对象具有的性质，推出一类事物中所有对象都具有的这类性质的推理方式
    * 从一般到特殊
    * 大前提，小前提，结论
* 确定性推理
    * 确定性逻辑推理：逻辑推理，具有完备的推理过程和充分的表达能力
    * 不确定性推理：根据以往的经验和分析，结合专家先验知识构建概率模型，并利用统计计数、最大化后验概率等统计学习的手段对推理假设进行验证或推测
        * 概率图模型：有向图贝叶斯网络，无向图马尔科夫网络
            * 基于和积变量消除的方法
            * 基于概率图结构的置信传播或期望传播的方法
        * 概率逻辑推理：弥补了概率图模型中缺乏可复用规则的特点；结构学习又可以称为概率逻辑推理模型下的规则自动挖掘；；迭代局部搜索代替全局搜索
        * 关联规则挖掘：路径排序算法是基于图模型上随机游走的启发式方法，通过枚举或抽样图上的两个节点间的路径，递归地计算两个点间的到达概率，对每个路径进行打分
* OWL本体语言：
    * 是知识图谱语言中最规范，最严谨，表达能力最强的语言；  
    基于RDF语法，使表示出来的文档具有语义理解的结构基础；  
    促进了统一词汇表的使用，定义了丰富的语义词汇；允许逻辑推理
    * 语法 ：Subject --Property--> Object
    * 逻辑基础：描述逻辑(Description Logic)：是基于对象的知识表示的形式化，也叫概念表示语言或术语逻辑。是一阶谓词逻辑的一个可判定子集
    * 描述逻辑系统：一个描述逻辑系统包括四个基本的组成部分
        1. 最基本的元素: 
            * 概念：一个领域的自己
            * 关系：该领域上的二元关系
            * 个体： 一个领域内的实例
        1. TBox：描述概念与关系的知识被成为公理，
            * 引入概念与关系的名称，声明包含关系的公理，知识形成“格”的结构
        1. ABox断言集 ：断言为ABox的外延知识
            * 一个对象/两个对象是否属于某个概念
        1. TBox和ABox上的推理机制
        * 不同的描述逻辑系统的表示能力与推理机制由于对这四个组成部分的不同选择而不同。
    * 逻辑描述语义
        * 原子概念A
        * 原子关系B
        * 合取：包含
        * 析取：或/互斥
        * 非
        * 存在量词，全称量词
    * 知识推理任务：
        1. 可满足性：本体/概念是否有模型
        1. 分类：计算新的概念包含关系
        1. 实例化：计算属于某个概念或关系的的所有实例集合
    * Tableaux运算：通过一系列规则构建Abox，检测满足性或检测实例是否存在于某概念
        1. 运算规则：
            * C⊓D(x)合取是∅，若C(x)，D(x)但都不在∅，则应将其加入∅
            * C(x)，D(x)不在∅，若C⊓D(x)为∅，则应将其加入∅
            * 若部分R.C(x)在∅，且R(x，y)与C(x)不在∅，则将其加入∅
            * 所有R.C(x)，R(x，y)在∅，如若C(y)不在∅，则将其加入∅
            * C ⊑D，若C(x)在∅但D(x)不在，则将D加入∅
        1. 正确性：基于Herbrand模型
### 本体推理相关工具
* FaCT++，Racer，Pellet，HermiT
* 基于逻辑编程改写的方法
    * 规则推理
        * 本体推理的局限：仅支持预定义的本体公理上的推理；用户无法定义自己的推理过程
        * 引入规则推理：可定制规则实现自定义的推理过程 -》Datalog语言可以结合本体推理和规则推理
    * Datalog语言：面向知识库于数据库设计的逻辑语言，支持递归，易于编写规则
        * 语法：原子Atom，规则Rule，事实Fact
    * 相关工具：KAON2，RDFox
* 基于产生式规则的方法：可以按照一定机制执行规则从而达到目标
    * 组成：事实集合，产生式/规则集合，推理引擎
        1. 事实集/运行内存：存储当前系统的所有事实
        1. 事实：描述对象，描述关系
        1. 产生式集合：条件组成集合LHS，动作组成集合RHS：if LHS then RHS
            * 条件(condition)的集合，各条件之间是且的关系当LHS中所有条件均被满足，则该规则触发。形如attr：sprc，后者约束前者，形式可为原子/变量/表达式/布尔/与或非
            * 动作类型：add，remove，modify
        1. 推理引擎：控制系统的执行
            * 模式匹配：RETE算法，用每条规则的条件部分匹配当前WM
            * 解决冲突：从被触发的多条规则中选择一i谈：随机选择，具体性，新进程度
            * 执行动作
    * 相关工具：Drools，Jena，RDF4J，GraphDB
* 基于并行技术的方法
    * 单机环境下多核心，多处理器技术
    * 多机环境下基于网络技术的分布式技术

## 课堂题目
1. 人工智能是一门以知识为核心的科学，主要研究  **知识的表示，知识的获取，知识的运用**
1. 知识表示有哪些用途 **用于高效计算的数据结构，客观事物的机器标识，人可理解的机器语言，人可理解的机器语言，支持推理**
1. 下列哪些是人工构建的知识图谱？ **CYC,worldNet**
1. 下列哪些是基于维基百科的知识图谱 **DBPedia,Yago,Freebase**
1. 用cycL表示小白是一只狗 **(#$isa #$Xiaobai #$Dog)**
1. 下列哪些是函数 **Father(Wang),Minus(3,2)**
1. 一阶谓词逻辑表示法的步骤是 **定义-赋值-逻辑联结**
1. 知识体系有哪三个方面核心内容 **对概念的分类,概念属性的描述,概念之间相互关系**
1. 领域概念抽取的步骤有哪些 **术语过滤,术语合并  抽取候选术语**
1. 实体对齐的对象是 **实体**，框架匹配的对象是 **概念、属性、关系**
1. 实体识别主要有哪些方法 **规则，机器学习**
1. 基于机器学习的实体识别方法主要包括哪几类 **特征，深度学习**
1. 细粒度实体识别的特点是 **类别具有层次结构,类别更多**
1. 实体消歧定义为 **6** 元组
1. 实体消歧六元组里最后一元δ代表 **实体消歧函数**
1. 实体消歧按照方法可分为哪几类 **基于聚类的实体消歧,基于实体链接的实体消歧**
1. 基于实体链接的方法输入端为 **待消歧实体指称项及其上下文信息,目标实体知识库**
1. 二元关系抽取可表示为 **（arg1, relation, arg2）**
1. 根据所抽取邻域的划分，关系抽取可分为 **开放域关系抽取,限定域关系抽取**
1. 下列哪些是全连接神经网络和CNN的区别 **全连接vs 局部连接,权重独立 vs 权重共享,一般不采样 vs 一般采样**
1. 词表示方法NNLM全称是 **Neural Network Language Model**
1. ACE实体分为 **8** 大类 **33** 小类
1. 



    