# 速通机器学习：从浑水摸鱼到游刃有余
## 前置科技
1. 线性代数
    * 不准确的说法：同时计算大量数据（标量->向量），跨维度映射
1. 计算速度
    * 受自然界启发的人工神经网络在起初时的计算量过大，又碰上了金融危机。直到英伟达的GPU解决计算问题，LeNet的全连接神经网络进行手写数字识别（2024年物理诺奖，足以说明其影响力）后才得以发展
        > 人工神经网络证明了人类对复杂系统的理解，我们不需要算出每一个原子的位置也能模拟宇宙
1. **Transformer**
    > 不要笑挑战:随机一篇人工智能论文,通过5次以内的引用跳转到Attention is All You Need(Transformer原论文)   

    流程如下,由3blue1brown的科普视频总结而来,只是简述推理过程,暂未提及反向传播:  
    1. 输入的文字分解为token,并对token进行编码(词向量嵌入),词向量的维度为12288(4096*3)
    1. 注意力机制,词向量间会互相沟通并调整自己的向量
        1. 词向量会经过两个矩阵,query查询矩阵,key键矩阵
            * 比如某查询矩阵的含义是查询自己前面有没有形容词,那么查询向量与符合要求的形容词的键值向量内积很大
        1. 对应计算点积并归一化,该值会作为该词的值向量的权重成为原词向量的修正
            * 在词向量空间中,一个复合概念可以由几个基础概念向量和修饰词向量相加得到,比如:  
            V[背带裤]+V[中分头]约等于V[蔡徐坤]
            * q,k矩阵12288 * 128的向量,v矩阵12288 * 12288
        * 像这样的q矩阵和k矩阵总共有96个,他们之间并行计算.所以称为多头注意力
    1. 多层感知机,每个词向量会
    1. 重复上述两个步骤若干次,最后的词向量经过反嵌入矩阵后形成对多个词的条件概率
        * 多层多头注意力会将所有细节集中于最后一个词向量


## Papers Summarize：
1. **Open-loop VLM Robot Planning: An Investigation of Fine-tuning and Prompt Engineering Strategies**
    * 西红柿鸡蛋式论文，但对新手来说刚好
        * GPT的出现极大的鼓舞了AI研究，尤其助长了LLM（large language model），顺带VLM（video language model）也沾了些光，将其代入机器人领域后发现**只需要自然语言就能简单控制机械结构或做出简单的任务规划**
            > CNC编程仔的工资已经够低了……,但我还是想把价格打下来（
        * 油然而生的对云端AI的不信任，更希望本地运行
    * 讨论方向：VideioLLaMA在整合过去信息，上下文，常识知识的能力，通过将训练集的视频转为多个问答
        * 结论：调不了——微调效果不明显，提示造成反作用
        * 在本论文中砍掉了音频组件（在完全体的模型中与视频组件同等地位），因为基准测试没有涉及到音频相关，这样也能减少训练内容
            * 视频逐帧切片后编码，结合查询向量与实践步长信息后线性映射为适合语言模型的特征向量
                > 这里面的每一个名词我都需要解释
        * 数据集：bingbingpongpong
        * 微调：
            > 调什么？怎么调？为啥调？我是谁？我在哪？我要干啥？
        * 评估方法：
            1. 基础方法：向VLM提供当前帧，过往关键帧，文本提示——高级任务目标，解释图片，下一步干嘛，然后做选择题
            1. 思维链：在提示的末尾添加了"Think step by step"
                > 9z？像极了我敲打GPT3的时候
            1. 自我反思：这道题做两次，第二次会包含第一次的结果并问"这是对的吗"，再作回答
            1. 自洽性：LLM会对同一个问题可能会做出不同的答案，但是挑回答的最多的那项能大幅提升准确性
        * 结果
            * 动词/名词的成功率与出现频率无关
            * 微调：
                1. 微调数据集：可能会影响其他数据集训练出来的效果，体现在评估与训练内容相似/不同的环境上
                1. 微调视觉编码器：加速适应，但不一定对泛化有用
                1. 参数数量：7b与13b的区别不大
            * 提示方法：
                1. 思维链：基本不影响，某个项目中出现了过拟合指令提示从而影响了指令接受
                1. 自我反省：对模型影响很小，但是会大幅影响一些项目——模型内省就错推错，没有起到预期作用，或者说压根没推理
                1. 自洽：唯一选择自由作答，使用推理链不会给出完整答案，使用Ego训练集的只会生成候选答案
            * 数据集分析：计算成对的欧几里得距离后再计算数据集中的Wasserstein-1 距离（**?**）
                * 视觉：通过预训练的CLIP模型。对训练集中随机视频帧提取视觉嵌入
                * 文字： fasttext-wiki-news-subwords300模型提取词嵌入
2. **Learning Transferable Visual Models From Natural Language Supervision(CLIP)**
    * 动机：预训练在NLP中掀起了一场革命，文本-文本输入输出中表现出极佳的零样本表现
        > 零样本：在数据集外的样本，类似于泛化，但是模型从未见识过  
        
        传统cv仍需监督学习有限分类的资料，  
    * 结构：类似于tf的单头注意力机制，但首先我们需要好好了解一下什么是transfomer：详见上文
